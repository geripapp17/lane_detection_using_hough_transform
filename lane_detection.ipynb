{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Detection using Hough Transform in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"data/lane1-straight.mp4\")\n",
    "output_path = Path(f\"output/{input_path.stem}-out{input_path.suffix}\")\n",
    "\n",
    "from moviepy.editor import *\n",
    "\n",
    "clip = VideoFileClip(filename=str(input_path))\n",
    "clip.ipython_display(width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "\n",
    "\n",
    "def process_frame(frame: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for processing and annotating a single frame.\n",
    "\n",
    "    Args:\n",
    "        frame:\n",
    "            Frame to process.\n",
    "\n",
    "    Returns:\n",
    "        Processed frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert colored frame to grayscale\n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Select specific intensity range (Thresholding)\n",
    "    img_gray_select = cv2.inRange(img_gray, 150, 255)\n",
    "\n",
    "    # Mask region of interest (ROI)\n",
    "    roi_vertices = np.array([[[100, 540], [900, 540], [525, 330], [440, 330]]])\n",
    "    img_gray_roi = mask_roi(frame=img_gray_select, vertices=roi_vertices)\n",
    "\n",
    "    # Edge detection\n",
    "    img_canny = cv2.Canny(image=img_gray_roi, threshold1=50, threshold2=100)\n",
    "    img_canny = cv2.GaussianBlur(src=img_canny, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    # Get Hough lines.\n",
    "    hough_lines = cv2.HoughLinesP(\n",
    "        image=img_canny,\n",
    "        rho=1,\n",
    "        theta=(np.pi / 180),\n",
    "        threshold=100,\n",
    "        lines=np.array([]),\n",
    "        minLineLength=50,\n",
    "        maxLineGap=300,\n",
    "    )\n",
    "\n",
    "    # Extrapolate Hough lines to left and right lanes.\n",
    "    img_lanes = get_lanes(frame, hough_lines, roi_upper_border=330, roi_lower_border=540)\n",
    "\n",
    "    # Combine original input frame with the extrapolated lanes.\n",
    "    image_result = cv2.addWeighted(src1=frame, alpha=1, src2=img_lanes, beta=0.4, gamma=0.0)\n",
    "\n",
    "    return image_result\n",
    "\n",
    "\n",
    "def mask_roi(frame: np.ndarray, vertices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mask the region of interest (ROI) from a defined list of vertices.\n",
    "\n",
    "    Args:\n",
    "        frame:\n",
    "            Input grayscale image.\n",
    "        vertices:\n",
    "            List containing the vertices of the mask polygon.\n",
    "\n",
    "    Returns:\n",
    "        Binary image masked with ROI.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros_like(frame)\n",
    "    cv2.fillPoly(img=mask, pts=vertices, color=255)\n",
    "\n",
    "    return cv2.bitwise_and(src1=frame, src2=mask)\n",
    "\n",
    "\n",
    "def get_lanes(frame: np.ndarray, lines: np.ndarray, roi_upper_border: int, roi_lower_border: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Function for getting the final extrapolated left and right lanes from the Hough lines.\n",
    "\n",
    "    Args:\n",
    "        frame:\n",
    "            Frame to process.\n",
    "        lines:\n",
    "            List containing line coordinates calculated with Hough Transform.\n",
    "        roi_upper_border:\n",
    "            Upper Y value of ROI.\n",
    "        roi_lower_border:\n",
    "            Lower Y value of ROI.\n",
    "\n",
    "    Returns:\n",
    "        Image containing only the extrapolated left and right lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract left and right lanes.\n",
    "    lines_left, lines_right = separate_left_right_lines(lines)\n",
    "    lane_left = extrapolate_lines(lines=lines_left, upper_border=roi_upper_border, lower_border=roi_lower_border)\n",
    "    lane_right = extrapolate_lines(lines=lines_right, upper_border=roi_upper_border, lower_border=roi_lower_border)\n",
    "\n",
    "    img_lanes = np.zeros(shape=(frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "    if lane_left is not None and lane_right is not None:\n",
    "        draw_lane_roi(frame=img_lanes, lanes=[lane_left, lane_right])\n",
    "\n",
    "    return img_lanes\n",
    "\n",
    "\n",
    "def separate_left_right_lines(lines) -> Tuple[List[List[int]]]:\n",
    "    \"\"\"\n",
    "    Function separating left and right lines depending on the slope.\n",
    "\n",
    "    Args:\n",
    "        lines:\n",
    "            List containing line coordinates calculated with Hough Transform.\n",
    "\n",
    "    Returns:\n",
    "        Left and right lines in separate lists.\n",
    "    \"\"\"\n",
    "\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if y1 > y2:  # Left line (negative slope)\n",
    "                    left_lines.append([x1, y1, x2, y2])\n",
    "                elif y1 < y2:  # Right line (positive slope)\n",
    "                    right_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "    return left_lines, right_lines\n",
    "\n",
    "\n",
    "def extrapolate_lines(lines: List[int], upper_border: int, lower_border: int) -> Optional[List[int]]:\n",
    "    \"\"\"\n",
    "    Function extrapolating lines keeping in mind the lower and upper border of ROI.\n",
    "\n",
    "    Args:\n",
    "        lines:\n",
    "            List containing line coordinates calculated with Hough Transform.\n",
    "        upper_border:\n",
    "            Upper Y value of ROI.\n",
    "        lower_border:\n",
    "            Lower Y value of ROI.\n",
    "\n",
    "    Returns:\n",
    "        Optional: List containing starting and ending coordinates of the extrapolated lane.\n",
    "    \"\"\"\n",
    "\n",
    "    slopes = []\n",
    "    consts = []\n",
    "\n",
    "    if len(lines):\n",
    "        for x1, y1, x2, y2 in lines:\n",
    "            slopes.append((y1 - y2) / (x1 - x2))\n",
    "            consts.append(y1 - slopes[-1] * x1)\n",
    "\n",
    "        avg_slope = sum(slopes) / max(1, len(slopes))\n",
    "        avg_consts = sum(consts) / max(1, len(consts))\n",
    "\n",
    "        # Calculate average intersection at lower_border.\n",
    "        x_lower_point = int((lower_border - avg_consts) / avg_slope)\n",
    "\n",
    "        # Calculate average intersection at upper_border.\n",
    "        x_upper_point = int((upper_border - avg_consts) / avg_slope)\n",
    "\n",
    "        return [x_lower_point, lower_border, x_upper_point, upper_border]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def draw_lane_roi(frame: np.ndarray, lanes: List[List[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Function filling in the lane ROI area.\n",
    "\n",
    "    Args:\n",
    "        frame:\n",
    "            Frame on which to draw the lanes.\n",
    "        lanes:\n",
    "            List containing the left and right extrapolated lanes.\n",
    "\n",
    "    Returns:\n",
    "        -\n",
    "    \"\"\"\n",
    "\n",
    "    points = []\n",
    "\n",
    "    x1, y1, x2, y2 = lanes[0]\n",
    "    points.append([x1, y1])\n",
    "    points.append([x2, y2])\n",
    "\n",
    "    x1, y1, x2, y2 = lanes[1]\n",
    "    points.append([x2, y2])\n",
    "    points.append([x1, y1])\n",
    "\n",
    "    points = np.array(points, dtype=\"int32\")\n",
    "\n",
    "    cv2.fillPoly(img=frame, pts=[points], color=(0, 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "video_cap = cv2.VideoCapture(str(input_path))\n",
    "if not video_cap.isOpened():\n",
    "    print(\"Error opening video stream or file.\")\n",
    "else:\n",
    "    # Get video properties\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "video_out = cv2.VideoWriter(str(output_path), fourcc, fps, (frame_width, frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(total=frame_count, desc=\"Processing\")\n",
    "while True:\n",
    "    has_frame, frame = video_cap.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "\n",
    "    frame_processed = process_frame(frame=frame)\n",
    "    video_out.write(frame_processed)\n",
    "\n",
    "    # progress_bar.update(1)\n",
    "\n",
    "video_out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
